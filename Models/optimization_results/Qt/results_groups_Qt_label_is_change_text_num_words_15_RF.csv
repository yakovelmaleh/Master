project_key,usability_label,features,feature_importance,accuracy_rf,confusion_matrix_rf,classification_report_rf,area_under_pre_recall_curve_rf,avg_precision_rf,area_under_roc_curve_rf,y_pred_rf,num_trees,max_features,max_depth,min_samples_split,min_samples_leaf,bootstrap
Qt,is_change_text_num_words_15,"['num_headlines', 'has_code', 'has_url', 'num_question_marks', 'has_template', 'len_sum_desc', 'num_sentences', 'num_words', 'has_acceptance_criteria', 'if_acceptance_empty_tbd', 'len_acceptance', 'avg_word_len', 'avg_num_word_in_sentence', 'has_tbd', 'has_please', 'len_description', 'if_description_empty_tbd', 'num_stopwords', 'num_issues_cretor_prev', 'priority', 'num_comments_before_sprint', 'num_changes_text_before_sprint', 'num_changes_story_point_before_sprint', 'original_story_points_sprint', 'time_until_add_sprint', 'noun_count', 'verb_count', 'adj_count', 'adv_count', 'pron_count', 'block', 'block_by', 'duplicate', 'relates', 'duplicate_by', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', 'ratio_unusable_issues_text_by_previous', 'dominant_topic_1']",0,0.9505271695052717,"[[1172    0]
 [  61    0]]","              precision    recall  f1-score   support

           0       0.95      1.00      0.97      1172
           1       0.00      0.00      0.00        61

    accuracy                           0.95      1233
   macro avg       0.48      0.50      0.49      1233
weighted avg       0.90      0.95      0.93      1233
",0.1063581545970915,0.1126825415963765,0.7299278240922061,[0 0 0 ... 0 0 0],1000,auto,80,2,2,True
